\documentclass[../../main.tex]{subfiles}
\begin{document}
\section{FEM computation of eigenvalues and eigenfunctions}
Let $H$ be a Hilbert space with the inner product $(\cdot,\cdot)$ and induced norm $||\cdot||$. Let $V$ be a linear subspace of $H$, with inner product defined by the bilinear form $b(\cdot,\cdot)$. It is assumed that this bilinear form $b$ is symmetric.

\subsection{General eigenvalue problem}


The following eigenvalue problem is considered in \cite{SF73}.


\subsubsection*{Problem E}
Find a vector $u \in V$ and number $\lambda \in R$ such that $u \neq 0$ and
\begin{equation}
	b(u,v) = \lambda (u,v) \label{GEVP}
\end{equation} for each $v \in V$.

Suppose $E^h$ is a finite dimensional subspace of $V$. Consider the Galerkin approximation for \eqref{GEVP}:
\subsubsection*{Problem $E^h$}
Find $u^h \in S^h$ such that $u^h \neq 0$ and \[b(u^h, v) = \lambda^h(u^h,v) \textrm{ for all } v \in S^h.\] 

For detail, see Chapter 5.

\textcolor{red}{********** need to move this ******************}

\subsection{Preliminary theory and notation}
In this section, the work in the textbook \cite{SF73} is discussed. The results are the same as given in the textbook, how ever the proofs are expanded for greater clarity.

Some theory is required before the main results can be proven. The theory is from \cite{SF73}.

\textcolor{red}{********** need to move this ******************}

\subsubsection*{Properties of eigenvalues}
It is well known that the eigenvalues of a eigenvalue problem such as \eqref{GEVP} form an infinite sequence of eigenvalues $(\lambda_i)$. Assume that the eigenvectors can be ordered in such a way that $\lambda_1 \leq \lambda_2 \leq \lambda_3 \leq ...$ where $\lambda_i$ are the corresponding eigenvalues.

Since any multiple of a eigenfunction is still an eigenfunction, the eigenfunctions can be normalized so that $||u_i|| = 1$ for all $i$.

Fix $m \in \mathbb{N}$. Let $\left\{ \phi_k \in V | k = 1,2,...,m \right\}$ be a set of linear independent admissible basis functions. Define $S^h := \text{span}\left\{\phi_k \in V | k = 1,2,...,m\right\}$ so that $S^h$ is a finite dimensional subspace of V. \label{sym:natural} \label{sym:Sh1}

Problem $E^h$ can be written as a matrix eigenvalue problem,
\begin{eqnarray*}
	\lambda^nM\bar{u}_n = K\bar{u}_n.
\end{eqnarray*} The pair $(\lambda^n, \bar{u}_n)$ correspond to the pair $(\lambda^h_k, u^h_k)$ which is the solution of Problem $E^h$.

In a finite-dimensional subspace, the ordering of vectors is preserved as it is in the original space. Denote the normalized eigenvectors in the space $S^h$ as $u^h_k$ with corresponding eigenvalues $\lambda^h_i$ for $k = 1,2,...,m$.

Also any subspace of $S^h$ will also be a subspace of $V$. So the minmax principle applies and a lower bound for the eigenvalues can be found:
\begin{equation}
	\lambda_i \leq \lambda_i^h.
\end{equation}

\subsubsection*{Properties of eigenvalues}
It is well known that the eigenvalues of a eigenvalue problem such as \eqref{GEVP} form an infinite sequence $(\lambda_i)$. Assume that the eigenvalues $\lambda_i$ can be ordered $\lambda_1 \leq \lambda_2 \leq \lambda_3 \leq ...$ and denote the corresponding eigenfunctions $u_i$.

Since any multiple of a eigenfunction is still an eigenfunction, the eigenfunctions can be normalized so that $||u_i|| = 1$ for all $i$.

Fix $m \in \mathbb{N}$. Let $\left\{ \phi_k \in V | k = 1,2,...,m \right\}$ be a set of linear independent admissible basis functions. Define $S^h := \text{span}\left\{\phi_k \in V | k = 1,2,...,m\right\}$ so that $S^h$ is a finite dimensional subspace of V. \label{sym:natural} \label{sym:Sh1}


The ordering of the eigenvalues remains valid in a finite dimensional space. The eigenvalues in the space $S^h$ is denoted as $\lambda_i^h$ with corresponding normalized eigenfunction $u^h_i$ for $i = 1,2,...,m$.

Also any subspace of $S^h$ will also be a subspace of $V$. So the minmax principle applies and a lower bound for the eigenvalues can be found:
\begin{equation}
	\lambda_i \leq \lambda_i^h.
\end{equation}


\subsection{Estimating the eigenvalues.}
\textbf{Rayleigh quotient}
\begin{equation*}
	R(v) = \frac{b(v,v)}{(v,v)} \ \text { for } v \in V.
\end{equation*} \label{sym:Rayleigh}

\textbf{minmax Principle}\\
Let T denote the class of subspaces of $V$ that jas dimension $j$. Then
\begin{equation*}
	\lambda_j = \min_{s\in T}\max_{v \in S} R(v).
\end{equation*}

\textbf{Rayleigh-Ritz Projection}\\
If $u \in V$, then $Pu$ is its projection in the subspace $S^h$.
\begin{equation*}
	b(u-Pu,v^h) = 0 \ \text{ for all } v \in S^h.
\end{equation*}

\subsubsection{The approximation theorem}

Consider a interpolation operator $\Pi$.\label{sym:interpolation} This projection is linear, i.e.
\begin{align*}
	\Pi(f + g) & = \Pi f + \Pi g,\\
	\Pi(\alpha f) & = \alpha \Pi f \ \text{ for a constant } \alpha. 
\end{align*}

Define the interval $I_e = [a, a+h]$. A necessary condition is for the operator $\Pi$ is that when $\Pi u$ is restricted to the interval $I_e$, this must equal the projection of $u$ restricted to the interval $I_e$. This can be written as
\begin{equation*}
	\left[ \Pi u \right]_{I_{e}} = \Pi_e [u]_{I_{e}}.
\end{equation*}

The following notation is introduced.
\begin{itemize}
	\item[] $\mathcal{P}_j(I_e)$: Is the set of all polynomials on the interval $I_e$ of degree at most $j$. \label{sym:poly}
	\item[] $r(\Pi_e)$: If the range of $\Pi_e$ is contained in $\mathcal{P}_j(I_e)$ and $k<j$ is the largest integer such that $\Pi_e f = f$ for each $f \in \mathcal{P}_j(I_e)$, then $r(\Pi_e) = k$.
	\item[] $s(\Pi_e)$: Is a integer and the largest order derivative used in the definition of $\Pi_e$.
\end{itemize}

From the textbook \cite{OR76}, the following approximation theorem for finite elements is given verbatim:
\newtheorem*{Interpolation}{Theorem}
\begin{Interpolation}[The Interpolation Theorem for Finite Elements] 
	Let $\Omega$ be an open bounded domain in $\mathcal{R}^n$ satisfying the cone condition. Let $k$ be a fixed integer and $m$ an integer such that $0\leq m \leq k+1$. Let $\Pi \in L(H^{k+1}(\Omega), H^{m}(\Omega))$ be such that
	\begin{eqnarray}
	    \Pi u = u \ \ \ \ \textrm{ for all } u \in \mathcal{P}_k(\Omega)
	\end{eqnarray}
	Then for any $u \in H^{k+1}(\Omega)$ and for sufficiently small $h$, there exists positive a constant $C$, independent of $u$ and $h$, such that
	\begin{eqnarray}
	    ||u - \Pi u||_{H^m(\Omega)} \leq C \frac{h^{k+1}}{p^m} |u|_H^{k+1}(\Omega)
	\end{eqnarray}
	where $|u|_H^{k+1}(\Omega)$ is the seminorm.
\end{Interpolation}

For the requirements of this dissertation, this can be simplified with an assumption. The assumption is that the basis of $S^h$ consists of polynomials. With this assumptions, the semi-norm $|u|_H$ is equal to the norm $||u||$. This approximation theorem can be rewritten as
\newtheorem{Interpolation_2}{Theorem}
\begin{Interpolation_2}
	Suppose there exists an integer $k$ such that for each element
	\begin{equation*}
		s(\Pi_e) + 1 \leq k \leq r(\Pi_e) +1.
	\end{equation*}
	Then there exists a constant $C$ such that for any $u \in C^k_+(I)$,
	\begin{equation*}
		||(\Pi u)^{(m)} - u^{(m)}|| \leq C h^{k-m} || u^{(k)}|| \ \text{ for } m = 0,1,...,k.
	\end{equation*}
\end{Interpolation_2}

This will be referred to as the approximation theorem in this section.

Let $E_j \in V$ denote the eigenspace spanned by the exact eigenvectors $\left\{u_1,u_2,...,u_j \right\}$ for $j = 1,2,...,m$.

Then consider the subspace $S_j$ where
\begin{equation*}
	S_j = PE_j \ \text{ for } j = 1,2,...,m.
\end{equation*} The elements $Py_i$ are the projections of the eigenfunctions $u_i$ into the space $S^h$. These projections $Py_i$ are not necessarily equal to $u^h_j \in S^h$, but it can be shown that they are close.

Let $B_m = \left\{u \in e_m \ | \ ||u|| = 1 \right\}$ and define $\mu_m = \inf\left\{(Pu,Pu \ | \ u \in B_m)\right\}$.

The next steps in the textbook \cite{SF73} contains proofs with multiple results. In an attempt to better understand the results, the proofs are broken up into smaller proofs.

The first step to obtain estimates for the eigenvalues, it to show that the elements of $B_m$ are linearly independent.

\newtheorem{Prop_1}{Proposition}
\begin{Prop_1}
 $\mu_{m} > 0$ if and only if $\dim S_{m} = m$. \label{sym:mu}
\end{Prop_1}
\begin{proof}
	To show that the dimension of $S_m = m$, suppose that the elements of $B_m$ are linearly dependent. Then there exists a $u \in B_m$ such that $Pu = 0$ and consequently $\mu_m = 0$. The result follows from the contra-positive.
\end{proof}

\newtheorem{Prop_2}[Prop_1]{Proposition} \label{Prop_2}
\begin{Prop_2}
	$\lambda^{h}_{m} \leq \max R(Pu) \ \text{ for } u \in B_{m}$\\
\end{Prop_2}
\begin{proof}
	Since $\dim S_{m} = m$, following from the minmax principle
	\begin{equation*}
		\lambda_m^h \leq \max R(v) \ \text{ for } v \in S_m.
	\end{equation*}

	Take an arbitrary nonzero $v \in S_m$. Then there exists a $Py \in E_m$ such that $v = Py$.\\
 
	Now we take an arbitrary $v \in S_{m}$, $v \neq 0$. Then there exists a $u \in E_{m}$ such that $Py = v$. This $Py$ is the projection into $S_m$ of some $u \in E_m$ (which is also $\displaystyle \frac{1}{||u||}u \in B_m$).\\
	
	Next a linearity property for $R$ can be proven. 
	\begin{eqnarray*}
	R(\frac{1}{||u||}u) &=& \frac{b\left(\frac{1}{||u||}u,\frac{1}{||u||}u\right)}{\left(\frac{1}{||u||}u,\frac{1}{||u||}u\right)},\\
						&=& \frac{b(u,u)}{(u,u)},\\
						&=& R(u).
	\end{eqnarray*}
	So finally,
	\begin{eqnarray*}
	\lambda_{m}^{h} &\leq & \max R(v) \ \text{ for } \ v \in S_{m},\\
						&=& \max R(Pu) \ \text{ for } \ u \in E_{m},\\
						&=& \max R(Pu) \ \text{ for } \ u \in B_{m}.
	\end{eqnarray*}
\end{proof}

%\newpage
In the textbook, the authors show that the eigenfunctions are orthogonal. But they do so using matrix representations of the eigenvalue problem. A different method can be used to show this.

Pick any $i,j \in \mathbb{N}$ such that $i,j \leq m$. Let $v_{i},v_{j} \in V$ be arbitrary, then
\begin{eqnarray*}
	b(u_{i},u_{i}) &=& \lambda_{i}( u_{i},u_{i}),\\
	b(u_{j},u_{j}) &=& \lambda_{j}( u_{j},u_{j}).
\end{eqnarray*}
Now pick $u_{i} = u_{j}$ and $u_{j} = u_{i}$. Then
\begin{eqnarray*}
	b(u_{i},u_{j}) &=& \lambda_{i}( u_{i},u_{j}),\\
	b(u_{j},u_{i}) &=& \lambda_{j}( u_{j},u_{i}).
\end{eqnarray*}
Then using the symmetry of $b(\cdot,\cdot)$ and $( \cdot, \cdot )$, and subtracting,
\begin{eqnarray*}
	0 &=& (\lambda_{i} - \lambda_{j})( u_{i}, u_{j} )
\end{eqnarray*}
So if $i \neq j$ then $\lambda_{i} \neq \lambda_{j}$.\\

Therefore $u_{i}$ and $u_{j}$ must be orthogonal. And as mentioned previously, $||u|| = 1$.


\newtheorem{Lem_1}{Lemma} \label{Lem_1}
\begin{Lem_1}
	$\displaystyle \lambda_{m}^{h} \leq \frac{\lambda_{m}}{u_{m}^{h}}$
\end{Lem_1}
\begin{proof}
	Consider the linearity of the bilinear form $b$, and fact that any $u \in E_m$ can be expressed as a linear combination $u = \sum_{i=1}^{m} c_{i}u_{i}$. Then
	\begin{eqnarray*}
	b(u,u) &=& b\left(\sum_{i=1}^{m} c_{i}u_{i},\sum_{j=1}^{m} c_{j}u_{j}\right),\\
			&=& \sum_{i=1}^{m} c_{i}\sum_{j=1}^{m} c_{j} b(u_{i},u_{j}).
	\end{eqnarray*}

	The summation parameters can be merged into a single parameter. Then
	\begin{eqnarray*}
		b(u,u)  & = & \sum_{i=1}^{m} c_{i}^{2} \lambda_{i} u_i,\\
				& \leq & \lambda_{m}\sum_{i=1}^{m} c_{i}^{2} u_i,\\
				& = & \lambda_{m}||u||^2.
	\end{eqnarray*} for all $u \in B_m$.\\
	
	
	And since $B_{m} \subset E_{m}$, $b(Pu,Pu) \leq \lambda_{m}$ for all $u\in B_{m}$\\
	
	Using the Rayleigh quotient, and the definition of $\mu_{m}^{h}$, 
	\begin{eqnarray*}
		R(Pu) &=& \frac{b(Pu,Pu)}{(Pu,Pu)},\\
			&=& \frac{b(Pu,Pu)}{||Pu||^{2}},\\
			&\leq & \frac{\lambda_{m}}{\mu_{m}^{h}}.
	\end{eqnarray*}

	Together with Proposition \ref{Prop_2} it follows that
	\begin{eqnarray*}
		\lambda_{m}^{h} \leq \frac{\lambda_{m}}{\mu_{m}^{h}}.
	\end{eqnarray*}
\end{proof}

Following Lemma \ref{Lem_1}, and since $\lambda_{i}^{h} \geq \lambda_{i}$ it follows that $0 < \mu_{m}^{h} \leq 1$. It is now possible to define the error estimate as given in \cite{SF73}:
\begin{eqnarray*}
	\sigma_{m}^{h} = 1 - \mu_{m}^{h}.
\end{eqnarray*}


\newtheorem{Cor_1}{Corollary}
\begin{Cor_1}
	$0 \leq \sigma_{m}^{h} < 1$ and $\lambda_{m}^{h} - \lambda_{m} \leq \lambda_{m}^{h}\sigma_{m}^{h}$
\end{Cor_1}
\begin{proof}
	Starting with the result of Lemma \ref{Lem_1},
	\begin{eqnarray*}
		\lambda_{m}^{h} & \leq & \frac{\lambda_{m}}{\mu_{m}^{h}}\\
		\lambda_{m}^{h}\mu_{m}^{h}& \leq & \lambda_{m} \\
		-\lambda_{m}& \leq & -\lambda_{m}^{h}\mu_{m}^{h} \\
		\lambda_{m}^{h} -\lambda_{m}& \leq & \lambda_{m}^{h} -\lambda_{m}^{h}\mu_{m}^{h}\\
		\lambda_{m}^{h} -\lambda_{m}& \leq & \lambda_{m}^{h}\sigma_{m}^{h}
		\end{eqnarray*}
\end{proof}

This corollary give a error estimate for the eigenvalues. To prove the convergence of the eigenvalues, it is necessary to prove that the error estimate $\sigma_{m}^{h}$ converges to zero as $h \rightarrow 0$.


\newtheorem{Prop_3}[Prop_1]{Proposition} \label{Prop_3}
\begin{Prop_3}
	$\sigma_{m}^{h} = \max\left\{ 2( u,u-Pu )-||u-Pu||^{2} \ | \ u \in B_{m} \right\}$
\end{Prop_3}
\begin{proof}
	Let $u \in B_{m}$. Then
	\begin{eqnarray*}
		||u - Pu||^{2} &=& ( u - Pu, u - Pu ), \\
						&=& ( u, u ) - 2 ( u, Pu ) + ( Pu, Pu ), \\
						&=& 2( u, u ) - 2 ( u, Pu ) + ( Pu, Pu ) - ( u, u ),\\
						&=& 2( u, u - Pu ) + ( Pu, Pu ) - ( u, u ).\\
	\end{eqnarray*}
	Rewriting gives
	\begin{eqnarray*}
		( u, u ) - ( Pu, Pu )  & = & 2( u, u - Pu ) - ||u - Pu||^{2}.
	\end{eqnarray*}

	Since $u \in B_{m}$, $||u||^{2} = 1$. So then
	\begin{eqnarray*}
		1 - ||Pu||^{2}  & = & 2( u, u - Pu ) - ||u - Pu||^{2}.
	\end{eqnarray*}

	On the right hand side, $1 - ||Pu||^{2} \leq 1 - \mu_{m}^{h} = \sigma_{m}^{h}$ for all $u \in B_{m}$. So then it must be that
	\begin{eqnarray*}
	\sigma_{m}^{h} = \max\left\{ 2( u,u-Pu )-||u-Pu||^{2} \ | \ u \in B_{m} \right \}
	\end{eqnarray*}
\end{proof}

Proposition \ref{Prop_3} is a result given in \cite{SF73} without explaining how it is derived.

Introduce some new notation for ease of writing. For any $u \in E_{m}$, let $u^{*} = \sum_{i=1}^{m} c_{i}\lambda_{i}^{-1}u_{i}$ where $u = \sum_{i=1}^{m} c_{i}u_{i}$.

\newtheorem{Prop_4}[Prop_1]{Proposition} \label{Prop_4}
\begin{Prop_4}
	For any $u \in E_{m}$
		\begin{eqnarray*}
		( u, u - Pu ) = b(u^{*} - Pu^{*}, u -Pu)
		\end{eqnarray*}
\end{Prop_4}
\begin{proof}
	For any $i = 1,2,...,m$,
	\begin{eqnarray*}
	\lambda_{i}( u_{i},u-Pu ) &=&  b(u_{i}, u-Pu),\\
								&=& b(u_{i}, u-Pu) - b(u-Pu,Pu_{i}) \ \textrm{ (Rayleigh-Ritz Projection)},\\
								&=&  b(u_{i}, u-Pu) - b(Pu_{i},u-Pu),\\
								&=&  b(u_{i}-Pu_{i}, u-Pu).
	\end{eqnarray*}
	Multiplying by $c_{i}\lambda_{i}^{-1}$ and summation over i gives:
	\begin{eqnarray*}
	\sum_{i=1}^{m} c_{i}\lambda_{i}^{-1}\lambda_{i}( u_{i},u-Pu ) &=& \sum_{i=1}^{m} c_{i}\lambda_{i}^{-1}b(u_{i}-Pu_{i}, u-Pu),\\
								&=& b(\sum_{i=1}^{m} c_{i}\lambda_{i}^{-1}u_{i}-\sum_{i=1}^{m} c_{i}\lambda_{i}^{-1}Pu_{i}, u-Pu),\\
										&=& b(u^{*}-Pu^{*}, u-Pu).
	\end{eqnarray*}
	Therefore $( u,u-Pu ) = b(u^{*}-Pu^{*}, u-Pu)$.
\end{proof}


\newtheorem{Lem_2}[Lem_1]{Lemma} \label{Lem_2}
\begin{Lem_2}
	$\sigma_{m}^{h} \leq \max \left\{2||u^{*}- Pu^{*}|| ||u-Pu|| \ | \ u \in B_{m} \right\}$
\end{Lem_2}
\begin{proof}
	From Proposition \ref{Prop_3},
	\begin{eqnarray*}
		\sigma_{m}^{h} & = & \max\left\{ 2( u,u-Pu )-||u-Pu||^{2} \ | \ u \in B_{m} \right\}, \\
					& \leq & \max\left\{ 2( u,u-Pu ) \ | \ u \in B_{m} \right\}. \\
	\end{eqnarray*}

	From Proposition \ref{Prop_4}, 
	\begin{eqnarray*}
		\sigma_{m}^{h} = \max\left\{ 2 b(u^{*}-Pu^{*}, u-Pu) \ | \ u \in B_{m} \right\}.
	\end{eqnarray*}

	Using the Schwartz inequality,
	\begin{eqnarray*}
		b(u^{*} - Pu^{*}, u -Pu) & \leq & ||u^{*} - Pu^{*}||||u -Pu||.
	\end{eqnarray*}

	Finally,
	\begin{eqnarray*}
		\sigma_{m}^{h} & \leq & \max\left\{ 2||u^{*}- Pu^{*}|| ||u-Pu|| \ | \ u \in B_{m} \right\}.
	\end{eqnarray*}
\end{proof}

\newtheorem{Prop_5}[Prop_1]{Proposition} \label{Prop_5}
\begin{Prop_5}
	For any $\epsilon > 0$, there exists a $\delta >0$ such that for $h<\delta$,
	\begin{eqnarray*}
	||u^{*} - Pu^{*}|| < \epsilon \ \textrm{ for each } u \in B_{m}\\
	||u - Pu|| < \epsilon \ \textrm{ for each } u \in B_{m}
	\end{eqnarray*}
\end{Prop_5}
\begin{proof}
	Consider a set of basis functions $\Phi \subset S^h$ such that $\phi^(k) = 0$ for each $\phi \in \Phi$.

	From the Rayleigh-Ritz Projection, $Pu$ is the closest element in $S^h$ to $u$. In particular, $||u-Pu||\leq ||u-\Pi u||$, where $\Pi u$ is the interpolation of $u$ into $S^h$.
	
	From the Approximation Theorem, is follows that
	\begin{eqnarray*}
		||u - \Pi u|| \leq Ch^{k}||u^{(k)}||
	\end{eqnarray*}

	So for any $\epsilon > 0$, a $\delta$ can be found such that if $h<\delta$ then
	\begin{eqnarray*}
		||u - Pu|| \leq ||u - \Pi u|| \leq \epsilon
	\end{eqnarray*}
	A similar argument for $||u^{*} - Pu^{*}||$ proves the theorem.
\end{proof}


\newtheorem{Lem_3}[Lem_1]{Lemma} \label{Lem_3}
\begin{Lem_3}
	For any $\epsilon >0$ there exists a $\delta > 0$ such that
	\begin{eqnarray*}
	\sigma_{m}^{h} < \epsilon \ \textrm{ if } \ h < \delta
	\end{eqnarray*}
\end{Lem_3}
\begin{proof}
	For any $\epsilon > 0$ there exists a $\delta > 0$ such that if $h<\delta$, then
	\begin{eqnarray*}
	||u-Pu|| < \epsilon \ \textrm{ for each } \ u \in B_{m}
	\end{eqnarray*}
	This result, together with Lemma \ref{Lem_2} and Proposition \ref{Prop_5} gives the result.
\end{proof}

\newtheorem{Lem_4}[Lem_1]{Lemma} \label{Lem_4}
\begin{Lem_4}
	There exists a $\delta > 0$ such that for $h < \delta$
	\begin{eqnarray*}
	\lambda_{m}^{h} - \lambda_{m} \leq 2\lambda_{m}\sigma_{m}^{h}
	\end{eqnarray*}
\end{Lem_4}
\begin{proof}
	Using Lemma \ref{Lem_3}, choose $\delta$ such that $\sigma_{m}^{h} < \frac{1}{2}$. Then by Lemma \ref{Lem_1} gives that $\lambda_{m}^{h} < 2\lambda_{m}$.\\
	
	So $\lambda_{m}^{h} - \lambda_{m} \leq 2\lambda_{m}\sigma_{m}^{h}$.
\end{proof}

The convergence of the eigenvalues are now proved.

\subsection{Convergence of the eigenfunctions}
The next step is to show the convergence of the eigenfunctions. The problem can be formulated using the following result.

\newtheorem{Lem_5}[Lem_1]{Lemma} \label{Lem_5}
\begin{Lem_5}
	\begin{eqnarray*}
		b(u_{m}-u_{m}^{h},u_{m}-u_{m}^{h}) &=& \lambda_{m}( u_{m}-u_{m}^{h},u_{m}-u_{m}^{h} ) + \lambda_{m}^{h} - \lambda_{m}
		\end{eqnarray*}
\end{Lem_5}
\begin{proof}
	\begin{eqnarray*}
		b(u_{m}-u_{m}^{h},u_{m}-u_{m}^{h}) &=& b(u_{m},u_{m}) - 2b(u_{m},u^{h}_{m}) + b(u^{h}_{m},u^{h}_{m}) \\
										&=& \lambda_{m} ( u_{m}, u_{m} ) - 2\lambda_{m} ( u_{m}, u^{h}_{m} ) + \lambda_{m}^{h}( u_{m}^{h},u_{m}^{h} )\\
										&=&  \lambda_{m} - 2\lambda_{m} ( u_{m}, u^{h}_{m} ) + \lambda_{m}^{h} \\
										&=& 2\lambda_{m} - 2\lambda_{m} ( u_{m}, u^{h}_{m} ) + \lambda_{m}^{h} - \lambda_{m}\\
										&=& \lambda_{m}( u_{m}-u_{m}^{h},u_{m}-u_{m}^{h}) + \lambda_{m}^{h} - \lambda_{m}
		\end{eqnarray*}
\end{proof}

It has been shown that the eigenvalues converge to the exact eigenvalues as $h \rightarrow 0$. So from this result, it only remains to show that $( u_{m}-u_{m}^{h},u_{m}-u_{m}^{h}) \rightarrow 0$ as $h \rightarrow 0$.

At this point, another assumption must be made. Assume that there are not eigenvalues with multiplicity more than 1. In other words, all the eigenvalues correspond only to one eigenfunction. In \cite{SF73}, the authors mention that for repeated eigenvalues, then the eigenfunctions can be chosen so that the main convergence results hold. This case is ommited in this dissertation.

\newtheorem{Lem_6}[Lem_1]{Lemma} \label{Lem_6}
\begin{Lem_6}
	For all m and j
	\begin{eqnarray*}
	(\lambda_{j}^{h} - \lambda_{m}) ( Pu_{m}, u_{j}^{h}) = \lambda_{m} ( u_{m}-Pu_{m},u_{j}^{h} )
	\end{eqnarray*}
\end{Lem_6}
\begin{proof}
	Since the term $\lambda_{m}( Pu,u^{h}_{j})$ appears on both sides of the equation, it is only required to show that
	\begin{eqnarray*}
		\lambda_{j}^{h}( Pu, u_{j}^{h} ) &=& \lambda_{m} ( u, u_{j}^{h} ).	
	\end{eqnarray*}
	Since both $u$ and $u_{j}^{h}$ are eigenfunctions, then
	\begin{eqnarray*}
		\lambda_{j}^{h}( Pu, u_{j}^{h} ) &=& b(Pu,u_{j}^{h})\\
		\lambda_{m} ( u, u_{j}^{h} ) &=& b(u,u_{j}^{h})
	\end{eqnarray*}

	Then equality follows from the definitions of the projection P.
\end{proof}

The set $\left\{u_{1}^{h},u_{2}^{h},...,u_{N}^{h}\right\}$ forms an orthonormal basis for $S^{h}$. The projection $Pu_{m}$ can be written as:
\begin{eqnarray}
	Pu_{m} &=& \sum_{j=1}^{N} ( P u_{m} ,u_{j}^{h}) u_{j}^{h}. \label{CV1}
\end{eqnarray}


From Lemma \ref{Lem_6}, it follows that $( P_{m},u_{j}^{h} )$ is small if $\lambda_{m}^{h}$ is not close to $\lambda_{j}$. Therefore (\ref{CV1}) tells us that $Pu_{m}$ is close to $u_{m}^{h}$. The estimate for $Pu_{m} - u_{m}^{h}$ will follow from this result.


Following the convergence of the eigenvalues, $\exists \rho > 0$ and $\exists \delta > 0$ such that if $h<\delta$,
\begin{eqnarray}
|\lambda_{m} - \lambda_{j}^{h}| &>& \rho \ \ \textrm{ for all } \ j = 1,2,...,N.
\end{eqnarray}
Therefore
\begin{eqnarray}
\frac{\lambda_{m}}{|\lambda_{m} - \lambda_{j}^{h}|} &\leq & \rho \ \ \textrm{ for all } \ j = 1,2,...,N.
\end{eqnarray}

To simplify the notation, let $\beta = (Pu_m,Pu_m^h)$.

\newtheorem{Lem_7}[Lem_1]{Lemma} \label{Lem_7}
\begin{Lem_7}
	\begin{eqnarray*}
		||Pu - \beta Pu^h_m||^{2} &\leq & {\rho}^{2} ||u_{m} - Pu_{m}||^{2}
	\end{eqnarray*}
\end{Lem_7}
\begin{comment}
\begin{proof}

Using Lemma \ref{Lem_6}:
\begin{eqnarray*}
||Pu - \beta u_{m}^{h}||^{2} &=& \sum_{j\neq m} \left(\frac{\lambda_{m}}{|\lambda_{m} - \lambda_{j}^{h}|}\right)^{2} ( u_{m} - Pu_{m} ,u_{j}^{h})^{2},\\
				&\leq & \rho^{2} \sum_{j\neq m} ( u_{m} - Pu_{m} ,u_{j}^{h})^{2}, \\
				&\leq & \rho^{2} \sum_{j=1}^{N} ( u_{m} - Pu_{m} ,u_{j}^{h})^{2}, \\
				& = & \rho^{2} ||u_m - Pu_m||^{2}.\\
\end{eqnarray*}
\end{proof}
\end{comment}

\newtheorem{Lem_8}[Lem_1]{Lemma} \label{Lem_8}
\begin{Lem_8}
	\begin{eqnarray*}
		||u_{m} - \beta u_{m}^{h}|| &\leq & \left(1+\rho\right)||u_{m}-Pu_{m}||
	\end{eqnarray*}
\end{Lem_8}
\begin{comment}
\begin{proof}
	\begin{eqnarray*}
	||u_{m} - \beta u_{m}^{h}|| & \leq & ||u_{m}-Pu_{m}|| + ||Pu_{m} - \beta u_{m}^{h}|| \\
				& \leq & \left(1+\rho\right)||u_{m}-Pu_{m}|| \ \ \textrm{ (by Lemma \ref{Lem_7})}
	\end{eqnarray*}
\end{proof}
\end{comment}

The proofs for lemma's \ref{Lem_7} and \ref{Lem_8} are given in \cite{SF73}.\\

So again using the Approximation Theorem, it follows that $||u_{m} - \beta u_{m}^{h}||\leq Ch^{k}||u^{k}||$.


\newtheorem{Lem_9}[Lem_1]{Lemma} \label{Lem_9}
\begin{Lem_9}
	\begin{eqnarray*}
		||u_{m} -  u_{m}^{h}|| &\leq & 2||u_{m}-\beta u^{h}_{m}||
	\end{eqnarray*}
\end{Lem_9}
\begin{proof}
	\begin{eqnarray*}
	||u_{m} - u_{m}^{h}|| &=& ||u_{m} - \beta u_{m}^{h} + \beta u_{m}^{h} - u_{m}^{h}||, \\
						& \leq & ||u_{m} - \beta u_{m}^{h}|| + ||\beta u_{m}^{h} - u_{m}^{h}||, \\
						& = & 2||u_{m} - \beta u_{m}^{h}||.	
	\end{eqnarray*}
\end{proof}

Therefore t $||u_{m} -  u_{m}^{h}|| \leq Ch^{k}||u^{k}||$. So for any $\epsilon >0$ , a $\delta >0$ can be found such that if $h < \delta$, $||u_{m} -  u_{m}^{h}|| < \epsilon$.
\end{document}
